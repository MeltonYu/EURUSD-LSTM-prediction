{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuki/quant_project/EURUSD-LSTM-prediction\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Append the parent directory to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Verify that the parent directory was added\n",
    "print(sys.path[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>PX_OPEN</th>\n",
       "      <th>PX_HIGH</th>\n",
       "      <th>PX_LOW</th>\n",
       "      <th>PX_LAST</th>\n",
       "      <th>EURUSDV1W Curncy</th>\n",
       "      <th>EURUSDV1M Curncy</th>\n",
       "      <th>EURUSDV1Y Curncy</th>\n",
       "      <th>EURUSD25R1M Curncy</th>\n",
       "      <th>EURON Curncy</th>\n",
       "      <th>...</th>\n",
       "      <th>GTFRF2Y Govt</th>\n",
       "      <th>GTFRF10Y Govt</th>\n",
       "      <th>GTFRF30Y Govt</th>\n",
       "      <th>SPX Index</th>\n",
       "      <th>VIX Index</th>\n",
       "      <th>SX5E Index</th>\n",
       "      <th>CPI YOY Index</th>\n",
       "      <th>EACPI Index</th>\n",
       "      <th>Last_Return</th>\n",
       "      <th>Predict_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/3/2003</td>\n",
       "      <td>1.1695</td>\n",
       "      <td>1.1722</td>\n",
       "      <td>1.1554</td>\n",
       "      <td>1.1580</td>\n",
       "      <td>11.3500</td>\n",
       "      <td>11.1500</td>\n",
       "      <td>11.2000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534</td>\n",
       "      <td>4.262</td>\n",
       "      <td>4.971</td>\n",
       "      <td>1029.85</td>\n",
       "      <td>19.50</td>\n",
       "      <td>2516.48</td>\n",
       "      <td>2.3</td>\n",
       "      <td>81.54</td>\n",
       "      <td>-0.009918</td>\n",
       "      <td>0.011226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/6/2003</td>\n",
       "      <td>1.1563</td>\n",
       "      <td>1.1723</td>\n",
       "      <td>1.1535</td>\n",
       "      <td>1.1710</td>\n",
       "      <td>10.6000</td>\n",
       "      <td>11.3500</td>\n",
       "      <td>11.2250</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>...</td>\n",
       "      <td>2.475</td>\n",
       "      <td>4.217</td>\n",
       "      <td>4.918</td>\n",
       "      <td>1034.35</td>\n",
       "      <td>19.51</td>\n",
       "      <td>2497.10</td>\n",
       "      <td>2.3</td>\n",
       "      <td>81.54</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>0.004355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/7/2003</td>\n",
       "      <td>1.1710</td>\n",
       "      <td>1.1814</td>\n",
       "      <td>1.1700</td>\n",
       "      <td>1.1761</td>\n",
       "      <td>11.2500</td>\n",
       "      <td>11.6500</td>\n",
       "      <td>11.4000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>...</td>\n",
       "      <td>2.476</td>\n",
       "      <td>4.249</td>\n",
       "      <td>4.959</td>\n",
       "      <td>1039.25</td>\n",
       "      <td>19.41</td>\n",
       "      <td>2476.61</td>\n",
       "      <td>2.3</td>\n",
       "      <td>81.54</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.004336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/8/2003</td>\n",
       "      <td>1.1761</td>\n",
       "      <td>1.1840</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.1812</td>\n",
       "      <td>11.1250</td>\n",
       "      <td>11.6250</td>\n",
       "      <td>11.3500</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>...</td>\n",
       "      <td>2.462</td>\n",
       "      <td>4.238</td>\n",
       "      <td>4.951</td>\n",
       "      <td>1033.78</td>\n",
       "      <td>19.18</td>\n",
       "      <td>2473.88</td>\n",
       "      <td>2.3</td>\n",
       "      <td>81.54</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>-0.005418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10/9/2003</td>\n",
       "      <td>1.1811</td>\n",
       "      <td>1.1860</td>\n",
       "      <td>1.1687</td>\n",
       "      <td>1.1748</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>11.3000</td>\n",
       "      <td>11.2000</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>-1.420</td>\n",
       "      <td>...</td>\n",
       "      <td>2.526</td>\n",
       "      <td>4.299</td>\n",
       "      <td>4.995</td>\n",
       "      <td>1038.73</td>\n",
       "      <td>18.82</td>\n",
       "      <td>2531.37</td>\n",
       "      <td>2.3</td>\n",
       "      <td>81.54</td>\n",
       "      <td>-0.005418</td>\n",
       "      <td>0.004256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>7/15/2024</td>\n",
       "      <td>1.0903</td>\n",
       "      <td>1.0922</td>\n",
       "      <td>1.0882</td>\n",
       "      <td>1.0894</td>\n",
       "      <td>4.6725</td>\n",
       "      <td>5.0475</td>\n",
       "      <td>6.1700</td>\n",
       "      <td>-0.1475</td>\n",
       "      <td>0.494</td>\n",
       "      <td>...</td>\n",
       "      <td>2.948</td>\n",
       "      <td>3.112</td>\n",
       "      <td>3.591</td>\n",
       "      <td>5631.22</td>\n",
       "      <td>13.12</td>\n",
       "      <td>4983.11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.58</td>\n",
       "      <td>-0.001192</td>\n",
       "      <td>0.000459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>7/16/2024</td>\n",
       "      <td>1.0894</td>\n",
       "      <td>1.0905</td>\n",
       "      <td>1.0872</td>\n",
       "      <td>1.0899</td>\n",
       "      <td>4.5475</td>\n",
       "      <td>5.0575</td>\n",
       "      <td>6.1750</td>\n",
       "      <td>-0.1450</td>\n",
       "      <td>0.499</td>\n",
       "      <td>...</td>\n",
       "      <td>2.914</td>\n",
       "      <td>3.081</td>\n",
       "      <td>3.560</td>\n",
       "      <td>5667.20</td>\n",
       "      <td>13.19</td>\n",
       "      <td>4947.83</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.58</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.003670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>7/17/2024</td>\n",
       "      <td>1.0899</td>\n",
       "      <td>1.0948</td>\n",
       "      <td>1.0895</td>\n",
       "      <td>1.0939</td>\n",
       "      <td>5.0075</td>\n",
       "      <td>5.2550</td>\n",
       "      <td>6.1750</td>\n",
       "      <td>-0.1375</td>\n",
       "      <td>0.498</td>\n",
       "      <td>...</td>\n",
       "      <td>2.924</td>\n",
       "      <td>3.075</td>\n",
       "      <td>3.551</td>\n",
       "      <td>5588.27</td>\n",
       "      <td>14.48</td>\n",
       "      <td>4891.46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.58</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>-0.003839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>7/18/2024</td>\n",
       "      <td>1.0939</td>\n",
       "      <td>1.0941</td>\n",
       "      <td>1.0894</td>\n",
       "      <td>1.0897</td>\n",
       "      <td>4.3325</td>\n",
       "      <td>5.0300</td>\n",
       "      <td>6.2175</td>\n",
       "      <td>-0.2125</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.909</td>\n",
       "      <td>3.091</td>\n",
       "      <td>3.579</td>\n",
       "      <td>5544.59</td>\n",
       "      <td>15.93</td>\n",
       "      <td>4870.12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.58</td>\n",
       "      <td>-0.003839</td>\n",
       "      <td>-0.001377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>7/19/2024</td>\n",
       "      <td>1.0897</td>\n",
       "      <td>1.0902</td>\n",
       "      <td>1.0876</td>\n",
       "      <td>1.0882</td>\n",
       "      <td>4.5875</td>\n",
       "      <td>5.0975</td>\n",
       "      <td>6.2550</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>1.480</td>\n",
       "      <td>...</td>\n",
       "      <td>2.923</td>\n",
       "      <td>3.133</td>\n",
       "      <td>3.626</td>\n",
       "      <td>5505.00</td>\n",
       "      <td>16.52</td>\n",
       "      <td>4827.24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.58</td>\n",
       "      <td>-0.001377</td>\n",
       "      <td>-0.000092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5426 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dates  PX_OPEN  PX_HIGH  PX_LOW  PX_LAST  EURUSDV1W Curncy  \\\n",
       "1     10/3/2003   1.1695   1.1722  1.1554   1.1580           11.3500   \n",
       "2     10/6/2003   1.1563   1.1723  1.1535   1.1710           10.6000   \n",
       "3     10/7/2003   1.1710   1.1814  1.1700   1.1761           11.2500   \n",
       "4     10/8/2003   1.1761   1.1840  1.1760   1.1812           11.1250   \n",
       "5     10/9/2003   1.1811   1.1860  1.1687   1.1748           11.5000   \n",
       "...         ...      ...      ...     ...      ...               ...   \n",
       "5422  7/15/2024   1.0903   1.0922  1.0882   1.0894            4.6725   \n",
       "5423  7/16/2024   1.0894   1.0905  1.0872   1.0899            4.5475   \n",
       "5424  7/17/2024   1.0899   1.0948  1.0895   1.0939            5.0075   \n",
       "5425  7/18/2024   1.0939   1.0941  1.0894   1.0897            4.3325   \n",
       "5426  7/19/2024   1.0897   1.0902  1.0876   1.0882            4.5875   \n",
       "\n",
       "      EURUSDV1M Curncy  EURUSDV1Y Curncy  EURUSD25R1M Curncy  EURON Curncy  \\\n",
       "1              11.1500           11.2000              0.7000        -1.055   \n",
       "2              11.3500           11.2250              0.7000        -0.335   \n",
       "3              11.6500           11.4000              0.8000        -0.345   \n",
       "4              11.6250           11.3500              0.8000        -0.373   \n",
       "5              11.3000           11.2000              0.7750        -1.420   \n",
       "...                ...               ...                 ...           ...   \n",
       "5422            5.0475            6.1700             -0.1475         0.494   \n",
       "5423            5.0575            6.1750             -0.1450         0.499   \n",
       "5424            5.2550            6.1750             -0.1375         0.498   \n",
       "5425            5.0300            6.2175             -0.2125         0.500   \n",
       "5426            5.0975            6.2550             -0.2500         1.480   \n",
       "\n",
       "      ...  GTFRF2Y Govt  GTFRF10Y Govt  GTFRF30Y Govt  SPX Index  VIX Index  \\\n",
       "1     ...         2.534          4.262          4.971    1029.85      19.50   \n",
       "2     ...         2.475          4.217          4.918    1034.35      19.51   \n",
       "3     ...         2.476          4.249          4.959    1039.25      19.41   \n",
       "4     ...         2.462          4.238          4.951    1033.78      19.18   \n",
       "5     ...         2.526          4.299          4.995    1038.73      18.82   \n",
       "...   ...           ...            ...            ...        ...        ...   \n",
       "5422  ...         2.948          3.112          3.591    5631.22      13.12   \n",
       "5423  ...         2.914          3.081          3.560    5667.20      13.19   \n",
       "5424  ...         2.924          3.075          3.551    5588.27      14.48   \n",
       "5425  ...         2.909          3.091          3.579    5544.59      15.93   \n",
       "5426  ...         2.923          3.133          3.626    5505.00      16.52   \n",
       "\n",
       "      SX5E Index  CPI YOY Index  EACPI Index  Last_Return  Predict_Return  \n",
       "1        2516.48            2.3        81.54    -0.009918        0.011226  \n",
       "2        2497.10            2.3        81.54     0.011226        0.004355  \n",
       "3        2476.61            2.3        81.54     0.004355        0.004336  \n",
       "4        2473.88            2.3        81.54     0.004336       -0.005418  \n",
       "5        2531.37            2.3        81.54    -0.005418        0.004256  \n",
       "...          ...            ...          ...          ...             ...  \n",
       "5422     4983.11            3.0       126.58    -0.001192        0.000459  \n",
       "5423     4947.83            3.0       126.58     0.000459        0.003670  \n",
       "5424     4891.46            3.0       126.58     0.003670       -0.003839  \n",
       "5425     4870.12            3.0       126.58    -0.003839       -0.001377  \n",
       "5426     4827.24            3.0       126.58    -0.001377       -0.000092  \n",
       "\n",
       "[5426 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_processing import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "# Set the random seed\n",
    "seed_value = 42\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "return_test_day = [1,3,5]\n",
    "prediction_parameters_dic = {\"Forecast period\":1, \"time_rolling_window\":22}\n",
    "\n",
    "\n",
    "df_Macro = pd.read_csv(\"../Data/EURUSD_Macro.csv\")\n",
    "df_Macro[\"Last_Return\"] =((df_Macro[\"PX_LAST\"].pct_change(periods=prediction_parameters_dic[\"Forecast period\"]))\n",
    "                          )\n",
    "\n",
    "df_Macro[\"Predict_Return\"] = ((df_Macro[\"PX_LAST\"].pct_change(periods=prediction_parameters_dic[\"Forecast period\"])\n",
    "                      .dropna(ignore_index = True)))\n",
    "\n",
    "df_Macro.dropna(inplace=True)\n",
    "df_Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dates', 'PX_OPEN', 'PX_HIGH', 'PX_LOW', 'PX_LAST', 'EURUSDV1W Curncy',\n",
       "       'EURUSDV1M Curncy', 'EURUSDV1Y Curncy', 'EURUSD25R1M Curncy',\n",
       "       'EURON Curncy', 'EURUSDVON Curncy', 'EUR1M Curncy', 'EUR12M Curncy',\n",
       "       'DXY Curncy', 'GOLDS Comdty', 'CL1 Comdty', 'FEDL01 Index',\n",
       "       'LF94TRUU Index', 'USGG2YR Index', 'USGG10YR Index', 'USGG30YR Index',\n",
       "       'GTDEM2Y Govt', 'GTDEM10Y Govt', 'GTDEM30Y Govt', 'GTFRF2Y Govt',\n",
       "       'GTFRF10Y Govt', 'GTFRF30Y Govt', 'SPX Index', 'VIX Index',\n",
       "       'SX5E Index', 'CPI YOY Index', 'EACPI Index', 'Last_Return',\n",
       "       'Predict_Return'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Macro.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001947\n"
     ]
    }
   ],
   "source": [
    "split_point = int(df_Macro.shape[0]*0.9)\n",
    "df_train = df_Macro.iloc[:split_point,:]\n",
    "df_test = df_Macro.iloc[split_point:,:]\n",
    "\n",
    "x_train = df_train.drop(columns=[\"Dates\",\"Predict_Return\"]).to_numpy()\n",
    "y_train = df_train.loc[:, \"Predict_Return\"].to_numpy()\n",
    "\n",
    "x_test = df_test.drop(columns=[\"Dates\",\"Predict_Return\"]).to_numpy()\n",
    "y_test = df_test.loc[:, \"Predict_Return\"].to_numpy()\n",
    "\n",
    "scale_x = StandardScaler()\n",
    "\n",
    "x_train_norm = scale_x.fit_transform(x_train)\n",
    "x_test_norm = scale_x.transform(x_test)\n",
    "\n",
    "time_delta = prediction_parameters_dic[\"time_rolling_window\"]\n",
    "x_train_norm_rolling,x_test_norm_rolling = rolling_split(x_train_norm,time_delta),rolling_split(x_test_norm,time_delta)\n",
    "y_train_rolling,y_test_rolling = y_train[time_delta-1:,...],y_test[time_delta-1:,...]\n",
    "\n",
    "threshold = threshold_search(y_train,1e-6)\n",
    "\n",
    "print(threshold)\n",
    "\n",
    "threshold = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "209\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "y_train_rolling_label , y_test_rolling_label  = labelize(y_train_rolling,threshold),labelize(y_test_rolling,threshold) \n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(torch.from_numpy(x_train_norm_rolling),torch.from_numpy(y_train_rolling_label).to(torch.int64))\n",
    "\n",
    "test_set = torch.utils.data.TensorDataset(torch.from_numpy(x_test_norm_rolling),torch.from_numpy(y_test_rolling_label).to(torch.int64))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=32,shuffle=True)\n",
    "\n",
    "real_results = test_set[:][1]\n",
    "\n",
    "print(len(real_results[real_results==0]))\n",
    "print(len(real_results[real_results==1]))\n",
    "print(len(real_results[real_results==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/miniconda3/envs/initial/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.75 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "import time_net\n",
    "\n",
    "hyperparas = {'input_dim':x_train.shape[-1],'hidden_dim':32,'hidden_nums':5,'output_dim':3,'block_layer_nums':2, 'LSTM_layer_nums':1\n",
    "        , 'dropout_rate':0.75}\n",
    "\n",
    "net_test = time_net.LSTM_Net(hyperparas=hyperparas)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "net_test.to(device=device,dtype=torch.float64)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train_epoch(loss_function, optimizer, model, loader,train_data,test_data):\n",
    "  loss_train = 0\n",
    "  loss_test = 0\n",
    "  \n",
    "  for(i, (x, y)) in enumerate(loader):\n",
    "    # Clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x=x.to(device=device)\n",
    "    y=y.to(device=device)\n",
    "    # Run a forward pass\n",
    "    outputs = model.forward(x)\n",
    "    # Compute the batch loss\n",
    "    loss = loss_function(outputs,y)\n",
    "    # Calculate the gradients\n",
    "    loss.backward()\n",
    "    # Update the parameteres\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "  with torch.no_grad():\n",
    "    train_outputs = model.forward(train_data[:][0].to(device=device))\n",
    "    train_loss = loss_function(train_outputs,train_data[:][1].to(device=device))\n",
    "    loss_train = train_loss.detach().cpu()\n",
    "    print(f\"train loss is {train_loss}\")\n",
    "    \n",
    "    test_outputs = model.forward(test_data[:][0].to(device=device))\n",
    "    test_loss = loss_function(test_outputs,test_data[:][1].to(device=device))\n",
    "    loss_test = test_loss.detach().cpu()\n",
    "    print(f\"test loss is {test_loss}\")\n",
    "        \n",
    "  return [loss_train, loss_test]   \n",
    "\n",
    "\n",
    "\n",
    "def train_model(loss_function, optimizer, model, loader,train_data,test_data,epochs=25):\n",
    "  loss_ls = []\n",
    "  \n",
    "  for i in range(epochs):\n",
    "    print(f\"-----------------------Epoch: {i+1}----------------------------------\")\n",
    "\n",
    "    loss_ls.append(train_epoch(loss_function, optimizer, model, loader,train_data,test_data))\n",
    "    \n",
    "  return loss_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Epoch: 1----------------------------------\n",
      "train loss is 1.614368512941274\n",
      "test loss is 1.6852098595912444\n",
      "-----------------------Epoch: 2----------------------------------\n",
      "train loss is 1.4871398275827943\n",
      "test loss is 1.5006140125131164\n",
      "-----------------------Epoch: 3----------------------------------\n",
      "train loss is 1.427833504572896\n",
      "test loss is 1.4412213885418694\n",
      "-----------------------Epoch: 4----------------------------------\n",
      "train loss is 1.385703525607457\n",
      "test loss is 1.3426188552376648\n",
      "-----------------------Epoch: 5----------------------------------\n",
      "train loss is 1.3264485367663033\n",
      "test loss is 1.400678720600103\n",
      "-----------------------Epoch: 6----------------------------------\n",
      "train loss is 1.2931373718142531\n",
      "test loss is 1.2763181809062871\n",
      "-----------------------Epoch: 7----------------------------------\n",
      "train loss is 1.2553490548426511\n",
      "test loss is 1.2680294843502884\n",
      "-----------------------Epoch: 8----------------------------------\n",
      "train loss is 1.2237918561307888\n",
      "test loss is 1.1788125665724305\n",
      "-----------------------Epoch: 9----------------------------------\n",
      "train loss is 1.2064469818765766\n",
      "test loss is 1.2600420026202852\n",
      "-----------------------Epoch: 10----------------------------------\n",
      "train loss is 1.1822603605390218\n",
      "test loss is 1.1830493080239477\n",
      "-----------------------Epoch: 11----------------------------------\n",
      "train loss is 1.1812675767710241\n",
      "test loss is 1.1731215051681159\n",
      "-----------------------Epoch: 12----------------------------------\n",
      "train loss is 1.1642808636383968\n",
      "test loss is 1.1758368075013301\n",
      "-----------------------Epoch: 13----------------------------------\n",
      "train loss is 1.156503400271103\n",
      "test loss is 1.1426868319028438\n",
      "-----------------------Epoch: 14----------------------------------\n",
      "train loss is 1.1535058328558057\n",
      "test loss is 1.1473895568049626\n",
      "-----------------------Epoch: 15----------------------------------\n",
      "train loss is 1.1370666252906052\n",
      "test loss is 1.1484896929486097\n",
      "-----------------------Epoch: 16----------------------------------\n",
      "train loss is 1.1340860898504406\n",
      "test loss is 1.1310176741760523\n",
      "-----------------------Epoch: 17----------------------------------\n",
      "train loss is 1.1374031488411582\n",
      "test loss is 1.1493004696709386\n",
      "-----------------------Epoch: 18----------------------------------\n",
      "train loss is 1.1183391770325681\n",
      "test loss is 1.1177595186338665\n",
      "-----------------------Epoch: 19----------------------------------\n",
      "train loss is 1.1108427054996715\n",
      "test loss is 1.1193501450511167\n",
      "-----------------------Epoch: 20----------------------------------\n",
      "train loss is 1.1161320931979137\n",
      "test loss is 1.1248996826825388\n",
      "-----------------------Epoch: 21----------------------------------\n",
      "train loss is 1.110924877321969\n",
      "test loss is 1.1052869513176995\n",
      "-----------------------Epoch: 22----------------------------------\n",
      "train loss is 1.110969826806332\n",
      "test loss is 1.1128635542445906\n",
      "-----------------------Epoch: 23----------------------------------\n",
      "train loss is 1.1023616014631974\n",
      "test loss is 1.127045345685424\n",
      "-----------------------Epoch: 24----------------------------------\n",
      "train loss is 1.101117874535413\n",
      "test loss is 1.1210110903613308\n",
      "-----------------------Epoch: 25----------------------------------\n",
      "train loss is 1.0987759638122796\n",
      "test loss is 1.1207306613661876\n",
      "-----------------------Epoch: 26----------------------------------\n",
      "train loss is 1.0974903881616662\n",
      "test loss is 1.1090294471623439\n",
      "-----------------------Epoch: 27----------------------------------\n",
      "train loss is 1.0981244020194325\n",
      "test loss is 1.1084112577617677\n",
      "-----------------------Epoch: 28----------------------------------\n",
      "train loss is 1.0962951023902936\n",
      "test loss is 1.0975942846062552\n",
      "-----------------------Epoch: 29----------------------------------\n",
      "train loss is 1.0897225955303185\n",
      "test loss is 1.1027916030705773\n",
      "-----------------------Epoch: 30----------------------------------\n",
      "train loss is 1.089775284729165\n",
      "test loss is 1.085022683197138\n",
      "-----------------------Epoch: 31----------------------------------\n",
      "train loss is 1.0965151416740166\n",
      "test loss is 1.0831818429339801\n",
      "-----------------------Epoch: 32----------------------------------\n",
      "train loss is 1.089814968181538\n",
      "test loss is 1.09939493056116\n",
      "-----------------------Epoch: 33----------------------------------\n",
      "train loss is 1.0866653970306086\n",
      "test loss is 1.1015842648702145\n",
      "-----------------------Epoch: 34----------------------------------\n",
      "train loss is 1.087005194247397\n",
      "test loss is 1.092660070183699\n",
      "-----------------------Epoch: 35----------------------------------\n",
      "train loss is 1.0849183399900009\n",
      "test loss is 1.0953742695666255\n",
      "-----------------------Epoch: 36----------------------------------\n",
      "train loss is 1.0838850568801386\n",
      "test loss is 1.0936571424072703\n",
      "-----------------------Epoch: 37----------------------------------\n",
      "train loss is 1.0855358577025762\n",
      "test loss is 1.0866236969923948\n",
      "-----------------------Epoch: 38----------------------------------\n",
      "train loss is 1.0818736835492224\n",
      "test loss is 1.0876636765250667\n",
      "-----------------------Epoch: 39----------------------------------\n",
      "train loss is 1.0783163752272402\n",
      "test loss is 1.0933197614071184\n",
      "-----------------------Epoch: 40----------------------------------\n",
      "train loss is 1.080259911278283\n",
      "test loss is 1.0898902961314583\n",
      "-----------------------Epoch: 41----------------------------------\n",
      "train loss is 1.084319714190787\n",
      "test loss is 1.095494698349149\n",
      "-----------------------Epoch: 42----------------------------------\n",
      "train loss is 1.0828163543876428\n",
      "test loss is 1.0962620606703397\n",
      "-----------------------Epoch: 43----------------------------------\n",
      "train loss is 1.08206616842273\n",
      "test loss is 1.0809889619167137\n",
      "-----------------------Epoch: 44----------------------------------\n",
      "train loss is 1.0787123545360238\n",
      "test loss is 1.1013259686408556\n",
      "-----------------------Epoch: 45----------------------------------\n",
      "train loss is 1.0811950186038042\n",
      "test loss is 1.1007806247013707\n",
      "-----------------------Epoch: 46----------------------------------\n",
      "train loss is 1.0790788932054207\n",
      "test loss is 1.0917051018367736\n",
      "-----------------------Epoch: 47----------------------------------\n",
      "train loss is 1.0778555322819015\n",
      "test loss is 1.0921145789727411\n",
      "-----------------------Epoch: 48----------------------------------\n",
      "train loss is 1.0769619263884442\n",
      "test loss is 1.0861285855282148\n",
      "-----------------------Epoch: 49----------------------------------\n",
      "train loss is 1.079923133088374\n",
      "test loss is 1.090821605373675\n",
      "-----------------------Epoch: 50----------------------------------\n",
      "train loss is 1.0758120014870014\n",
      "test loss is 1.0929644971555537\n",
      "-----------------------Epoch: 51----------------------------------\n",
      "train loss is 1.0787701096699263\n",
      "test loss is 1.0893559248531364\n",
      "-----------------------Epoch: 52----------------------------------\n",
      "train loss is 1.0788820336700653\n",
      "test loss is 1.0957943380154576\n",
      "-----------------------Epoch: 53----------------------------------\n",
      "train loss is 1.0766901154482933\n",
      "test loss is 1.1015919906127392\n",
      "-----------------------Epoch: 54----------------------------------\n",
      "train loss is 1.075507291244685\n",
      "test loss is 1.0765193240870037\n",
      "-----------------------Epoch: 55----------------------------------\n",
      "train loss is 1.074332510002861\n",
      "test loss is 1.0911186692611388\n",
      "-----------------------Epoch: 56----------------------------------\n",
      "train loss is 1.0769593352945601\n",
      "test loss is 1.0859451535027458\n",
      "-----------------------Epoch: 57----------------------------------\n",
      "train loss is 1.0733028520058054\n",
      "test loss is 1.0845880193284338\n",
      "-----------------------Epoch: 58----------------------------------\n",
      "train loss is 1.0769383459555728\n",
      "test loss is 1.088958211096194\n",
      "-----------------------Epoch: 59----------------------------------\n",
      "train loss is 1.0765036179395364\n",
      "test loss is 1.0920751769061816\n",
      "-----------------------Epoch: 60----------------------------------\n",
      "train loss is 1.0731875017806953\n",
      "test loss is 1.0864341656218226\n",
      "-----------------------Epoch: 61----------------------------------\n",
      "train loss is 1.0736827845798786\n",
      "test loss is 1.080676725891409\n",
      "-----------------------Epoch: 62----------------------------------\n",
      "train loss is 1.07410993757821\n",
      "test loss is 1.0873525911827218\n",
      "-----------------------Epoch: 63----------------------------------\n",
      "train loss is 1.0727387127841912\n",
      "test loss is 1.0907332572783972\n",
      "-----------------------Epoch: 64----------------------------------\n",
      "train loss is 1.0734392887915651\n",
      "test loss is 1.0801861955722172\n",
      "-----------------------Epoch: 65----------------------------------\n",
      "train loss is 1.0710811449085873\n",
      "test loss is 1.0843173554048158\n",
      "-----------------------Epoch: 66----------------------------------\n",
      "train loss is 1.072295646368967\n",
      "test loss is 1.087282334708995\n",
      "-----------------------Epoch: 67----------------------------------\n",
      "train loss is 1.0722653555438735\n",
      "test loss is 1.0894012268000874\n",
      "-----------------------Epoch: 68----------------------------------\n",
      "train loss is 1.0707000193098681\n",
      "test loss is 1.0925681125237745\n",
      "-----------------------Epoch: 69----------------------------------\n",
      "train loss is 1.0712322126425087\n",
      "test loss is 1.0835769336714867\n",
      "-----------------------Epoch: 70----------------------------------\n",
      "train loss is 1.0713871233259924\n",
      "test loss is 1.0832611625549697\n",
      "-----------------------Epoch: 71----------------------------------\n",
      "train loss is 1.0686642227527465\n",
      "test loss is 1.0904783569181988\n",
      "-----------------------Epoch: 72----------------------------------\n",
      "train loss is 1.071253512600656\n",
      "test loss is 1.086887851133509\n",
      "-----------------------Epoch: 73----------------------------------\n",
      "train loss is 1.0730917891357057\n",
      "test loss is 1.084360905278109\n",
      "-----------------------Epoch: 74----------------------------------\n",
      "train loss is 1.0683542158424482\n",
      "test loss is 1.0795908870171849\n",
      "-----------------------Epoch: 75----------------------------------\n",
      "train loss is 1.0694084883195936\n",
      "test loss is 1.0792630386847897\n",
      "-----------------------Epoch: 76----------------------------------\n",
      "train loss is 1.0712936627886915\n",
      "test loss is 1.0859660613115207\n",
      "-----------------------Epoch: 77----------------------------------\n",
      "train loss is 1.0692762111367071\n",
      "test loss is 1.0919438635213323\n",
      "-----------------------Epoch: 78----------------------------------\n",
      "train loss is 1.0684464365300732\n",
      "test loss is 1.081878649169101\n",
      "-----------------------Epoch: 79----------------------------------\n",
      "train loss is 1.0662745386876042\n",
      "test loss is 1.0893258421649057\n",
      "-----------------------Epoch: 80----------------------------------\n",
      "train loss is 1.0673178547580964\n",
      "test loss is 1.0919528007766939\n",
      "-----------------------Epoch: 81----------------------------------\n",
      "train loss is 1.0666154368953678\n",
      "test loss is 1.0852931274771587\n",
      "-----------------------Epoch: 82----------------------------------\n",
      "train loss is 1.0664887931064067\n",
      "test loss is 1.0806724263297447\n",
      "-----------------------Epoch: 83----------------------------------\n",
      "train loss is 1.0669192947272086\n",
      "test loss is 1.0852742763270269\n",
      "-----------------------Epoch: 84----------------------------------\n",
      "train loss is 1.067364794564779\n",
      "test loss is 1.0768225922268702\n",
      "-----------------------Epoch: 85----------------------------------\n",
      "train loss is 1.0666987445319007\n",
      "test loss is 1.0838512187644735\n",
      "-----------------------Epoch: 86----------------------------------\n",
      "train loss is 1.0677893157499438\n",
      "test loss is 1.087366923270306\n",
      "-----------------------Epoch: 87----------------------------------\n",
      "train loss is 1.0678521256486988\n",
      "test loss is 1.088794171515177\n",
      "-----------------------Epoch: 88----------------------------------\n",
      "train loss is 1.0675290049660544\n",
      "test loss is 1.083284645148261\n",
      "-----------------------Epoch: 89----------------------------------\n",
      "train loss is 1.0666433901983219\n",
      "test loss is 1.081609569587172\n",
      "-----------------------Epoch: 90----------------------------------\n",
      "train loss is 1.0664346658251824\n",
      "test loss is 1.081283665233103\n",
      "-----------------------Epoch: 91----------------------------------\n",
      "train loss is 1.0649244583039947\n",
      "test loss is 1.0835295725743774\n",
      "-----------------------Epoch: 92----------------------------------\n",
      "train loss is 1.0679993956886804\n",
      "test loss is 1.0870351118300032\n",
      "-----------------------Epoch: 93----------------------------------\n",
      "train loss is 1.0648290418804829\n",
      "test loss is 1.0914668917768973\n",
      "-----------------------Epoch: 94----------------------------------\n",
      "train loss is 1.0640744542048148\n",
      "test loss is 1.0902112008958094\n",
      "-----------------------Epoch: 95----------------------------------\n",
      "train loss is 1.0629538926431243\n",
      "test loss is 1.0889903708329904\n",
      "-----------------------Epoch: 96----------------------------------\n",
      "train loss is 1.062415328422617\n",
      "test loss is 1.0841837214083123\n",
      "-----------------------Epoch: 97----------------------------------\n",
      "train loss is 1.0665875809603054\n",
      "test loss is 1.08044050026204\n",
      "-----------------------Epoch: 98----------------------------------\n",
      "train loss is 1.0647317870107553\n",
      "test loss is 1.0836571137441384\n",
      "-----------------------Epoch: 99----------------------------------\n",
      "train loss is 1.0617737173053858\n",
      "test loss is 1.0868887673427672\n",
      "-----------------------Epoch: 100----------------------------------\n",
      "train loss is 1.062286707223043\n",
      "test loss is 1.0965120003897832\n"
     ]
    }
   ],
   "source": [
    "optim_Adam = torch.optim.Adam(net_test.parameters(),lr = 0.0001)\n",
    "epochs = 100\n",
    "loss_ls = train_model(loss_function=loss,optimizer=optim_Adam,model=net_test,loader=train_loader,train_data=train_set,\n",
    "                      test_data=test_set,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/miniconda3/envs/initial/lib/python3.12/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/yuki/miniconda3/envs/initial/lib/python3.12/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(data=np.array(loss_ls),columns=[\"Train_loss\", \"Test_loss\"])\n",
    "seaborn.lineplot(data=loss_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39846743295019155"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "net_test.to(device=torch.device(\"cpu\"))\n",
    "net_test.eval()\n",
    "\n",
    "predict_probability = torch.max(F.softmax(net_test(test_set[:][0]),dim=-1),dim=-1)[0]\n",
    "\n",
    "predict_results = torch.argmax(F.softmax(net_test(test_set[:][0]),dim=-1),dim=-1)\n",
    "real_results = test_set[:][1]\n",
    "\n",
    "accuracy_score(real_results,predict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31976744186046513"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_predict_bool = (predict_results != 1) \n",
    "\n",
    "act_predict_results = predict_results[act_predict_bool]\n",
    "act_real_results = real_results[act_predict_bool]\n",
    "\n",
    "accuracy_score(act_predict_results,act_real_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([172])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_predict_results.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = \"../trained_model/EURUSD_Mac_LSTM.pth\"\n",
    "\n",
    "torch.save(net_test.state_dict(),saved_path )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
